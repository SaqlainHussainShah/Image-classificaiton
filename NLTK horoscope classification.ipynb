{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ebryx/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ebryx/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "# from xml.dom import minidom\n",
    "from lxml import etree\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to read All csv ::  0.07196521759033203  seconds \n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "path='./dataset/blogs_train/'\n",
    "all_files = glob.glob(path + \"/*.xml\")\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "  # print(\"file name \", filename)\n",
    "  li.append(filename)\n",
    "    \n",
    "\n",
    "t2=time.time()\n",
    "print(\"time taken to read All csv :: \", t2-t1, \" seconds \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_file_names(li):\n",
    "  # names_list=[]\n",
    "  # for i in range(len(li)):\n",
    "  name_list=li.split('/')[-1]\n",
    "  return name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_attributes_from_name(name):\n",
    "  # data_object=[]\n",
    "  # for data in range(len(names_list)):\n",
    "  #   dummy_var=names_list[data].split('.')\n",
    "  #   dummy_object={'id':dummy_var[0], 'gender':dummy_var[1],\n",
    "  #                 'age':dummy_var[2], 'category':dummy_var[3],\n",
    "  #                 'horoscope':dummy_var[4]\n",
    "  #                 }\n",
    "  #   data_object.append(dummy_object)\n",
    "  dummy_var=name.split('.')\n",
    "  data_object={'id':dummy_var[0], 'gender':dummy_var[1],\n",
    "                  'age':dummy_var[2], 'category':dummy_var[3],\n",
    "                  'horoscope':dummy_var[4]\n",
    "                }\n",
    "  \n",
    "  return data_object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = etree.XMLParser(encoding='ISO-8859-1', recover = True, huge_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import \tWordNetLemmatizer\n",
    "def clean_my_string(mystring):\n",
    "#     mystring=mystring.replace('..', \"\")\n",
    "\n",
    "#     mystring=sent_tokenize(mystring)    \n",
    "#     words = word_tokenize(mystring)\n",
    "    \n",
    "#     ps = PorterStemmer()\n",
    "#     sentence=''\n",
    "#     for w in words:\n",
    "#         rootWord=ps.stem(w)\n",
    "#         sentence+= \" \" + rootWord\n",
    "    clean_string=[]\n",
    "    \n",
    "    for i in range(len(mystring)): \n",
    "    \n",
    "    \n",
    "\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        sentence=''\n",
    "        tokenization = nltk.word_tokenize(mystring[i])\n",
    "        for w in tokenization:\n",
    "            rootWord=wordnet_lemmatizer.lemmatize(w)\n",
    "            sentence+= \" \" + rootWord\n",
    "        \n",
    "        clean_string.append(sentence)\n",
    "    mystring=clean_string\n",
    "    \n",
    "#     mystring=remove_stop_words(sentence)\n",
    "    return mystring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "  \n",
    "def remove_stop_words(mystring):  \n",
    "    \n",
    "    \n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    \n",
    "    filtered_string=[]\n",
    "    \n",
    "    for i in range(len(mystring)):\n",
    "        word_tokens = word_tokenize(mystring[i]) \n",
    "\n",
    "#     filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "        filtered_sentence = [] \n",
    "\n",
    "        for w in word_tokens: \n",
    "            if w not in stop_words: \n",
    "                filtered_sentence.append(w) \n",
    "                \n",
    "        filtered_string.append(filtered_sentence)\n",
    "    return filtered_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml(li):\n",
    "  all_objects=[]\n",
    "  for i in range(len(li)):\n",
    "    # print(\"i will run \", i+1,\" times\")\n",
    "    name_of_file=clean_file_names(li[i])\n",
    "    # print(name_of_file)\n",
    "    data_object=get_attributes_from_name(name_of_file)\n",
    "    # print(data_object)\n",
    "\n",
    "    post_text='  '\n",
    "    tree = etree.parse(li[i], parser=parser)\n",
    "    root = tree.getroot()\n",
    "    for element in root.iter():\n",
    "        if element.tag == 'post':\n",
    "            element_text = element.text\n",
    "            post_text = post_text + element_text\n",
    "    mystring = post_text.replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "    mystring = mystring.replace('   ', '').replace('\\\\','')\n",
    "   \n",
    "\n",
    "#     mystring=clean_my_string(mystring)\n",
    "   \n",
    "    # print(mystring)\n",
    "    # name_of_file=clean_file_names(li[i])\n",
    "    # data_object=get_attributes_from_name(name_of_file)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    data_object['posts']=mystring   \n",
    "    all_objects.append(data_object)\n",
    "\n",
    "  return all_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=time.time()\n",
    "data=read_xml(li[0:])\n",
    "t2=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to read ::  0.17442692756652833\n"
     ]
    }
   ],
   "source": [
    "print(\"time taken to read :: \", (t2-t1)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Im currently updating my site. And almost doing nothing else, By the way, my url is http://jcbylon.tripod.com, take a look at it if you have the time. Today my dad and I went swimming and tennis. We were only biking to the swimming pool (resort). then my dad decided to use my other bike to have them fixed. We are also planning to go scuba diving tomorrow in Batangas, that will be my first check-out (term for scuba dive out in the sea). My first day of school in Manila will be on Monday, thats in the Philippine Christian University, im quite nervous.  Im losing my temper now. Ive been posting for 2 times now, and It wont post. Well, loging out now, tell you about scuba diving  next time. If It still wont post Im not posting again. Im so havent yet got used to blogger. I always click on the wrong link. Well just wanted to tell yah about  urlLink emode.com . It gives you a quick IQ test and tells you to what category you\\'re knowledge falls, like me im a spatial (spatial or visual? I dont really remember) mathematician. And it quite surprises me because Im so never gonna be a mathematician, but base on what they explained to me, they were quite right. Well, I provided you the address so be sure to log-on cause its more than just IQ tests.  urlLink INFOHUB*  First, well actually my second day of school. Pretty long day of ten hours listening to you\\'re teachers and you\\'re new classmates chattering to each other if not to you. Got over ten subjects, and I just finished a few of my assignment. I actually got lost at the LRT today as I was going home. I got a station farther from where I was supposed to be. Well, got more things to do to the web so see yah! : )  Scuba diving was great. What experienced divers said was true, it was like entering a new world, everything seemed new to me. Well, it was surely different from staying in an aquarium-fish store so it was really new to me. While we had\\'nt found a house here in Manila yet, Im staying here in my sisters house, so Im close to school, and she also has a weblog of her own, but im not telling you the address. Well, I hope there wont be any problem occuring this time on posting my blogs. Bye : )  I so hate smoking, I dont know why, but even if nobody told me not to smoke, I still would never smoke. I guess Im starting to get more conscious about myself, like food and about smoking, experts say that even if you dont smoke, you would still get cancer and other smoking diseases if you inhale smoke from other smokers constantly. Oh well, just a little knowledge to share to you guys. Bye : )  More changes are happening to my former personal webpage. Its now  urlLink INFOHUB*,  and this is now my personal webpage. Please come and visit it, its really cool. I also have a fansite on scooby doo, but the url is pretty long so I cant tell you. Well nothing much to tell you so see you soon bye : ) Often times I feel wavy, maybe because of constant riding at the LRT. I really got nothin\\' to say right now, but I just feel like updating my blog. Well, got more things to do, Bye : ) Boy, its quite a while since I last blogged. Well, I just gone through the elimination round of the declamation contest at school yesterday. It was quite a competition, seeing how others did it. I still dont know who won though, for I wasnt able to come to school today. My second update for the year 2003, I guess its for the reason that nobody comes to see my blog anyway. Well, I just want to say that there\\'s been a lot of things that happened in my life recently. Well, its been almost four months, of course things will happen.To start, I want you all to see my new websites;  urlLink insideHogwarts  - a Harry Potter site, and. Oh, I forgot, I only have one new site, and thats\\'s it.Also, I have read a new book entitled; \"A Series of Unfortunate Events - The Bad Beginning\". I thing its a seven part book written by Lemony Snicket. Its full of.unfortunate events, like the title doesnt say enough. Its about the experiences of three siblings after their parents\\'s tragic death. Its also pretty funny and hilarious, maybe its one of the author\\'s ways of compensating the tragically depressing events.  I cant seem to remember anything else aside from the movies I watched recently, like X-Men2, The Core, etc. So, I leave you guys now and hope to update sooner than 4 months. =PHey there! Im planning to use a new template that I found from a website that provides different site lay-outs. I will use it once I finish adding some finishing touches to it. There\\'s also been loads of updates on my  urlLink Harry Potter  site, dont forget to visit it. But sadly, no updates from  urlLink FanMania2000 . Im also planning to get my own domain and have all my sites hosted in it. But I cant yet cause I dont have a credit card.maybe I can ask my sister.  Anyway, dont forget to visit my sites, and get in contact with me through e-mail; jcbylon@yahoo.com! Just an update on some recent eventsYesterday  - Posted a poem about something my crush said that really hurt me. I guess that\\'s whats wrong with most people, and even me sometimes, they dont really think before they speak and with that, they unknowingly hurt others feelings :(Today  - Woke up, ate breakfast, took a bath, brushed my teeth, got dressed and attended the Reserve Officers Training Corps w/c is a requirement here in college every saturday. Just started working on the riffle today actually and it was cool. After that, went to this place called \"Sans Rival\" toeat spaghetti and a slice of cake with my friends. After that, went to the boulevard and took some walk and after a few paces, just saw our president having lunch on some kind of function or something. Anyway. Just realized that, 3 of my friends and I are there walking, strolling, while the President of the Philippines is just a few feet away. i dont know what came over me. but. (what the heck!!!) just forget about it. hehe  Anyway, after that, just went to fetch another friend and here we are now in the cafe. Tonight will actually be our all-dormitory acquaintance party. See yah there ;p  22766 \"II\" - The Words You Just SaidPlease dont I cant bare it I feel scared I cant take it  The words you just told me The moment it came out of your lips As if a sharp wooden arrow Shot out of a bow  It hit me Hit me hard in case you dont know As if my whole body suddenly sank on snow Not just skin deep, but down to my very bone  Now Im left here Pondering on what you just said More self-assuring than being deaf I\\'d rather have myself be dead Just thought I\\'d drop a few words.  Last Tuesday was actually my birthday. heck, it was definitely one of those days, everything just goes your way. This saturday will be our all-dormitory acquaintance party. ;) quite excited about that. hehe.  Anyway, thats about it. come visit my website by the way.  urlLink www.chocolate-cloud.tk . And thats about it. see yah all soon! Mwahh ;p I can see a lot have change here on blogger. Then so should I and this blog of mine. As you can notice on the lay-out, there has been a lot of new addition to bloggers templates so I felt oblidged to use a new one. I also changed the title, Im not sure why I chose those words, I guess it has been in my mind for quite a long time that thats all I can think of for the moment. And besides, I like the sound of it. And for the \"confessed virgin\" thing, dont ask!!!  I just posted a poem, you can read it below and yes, Im in love (heck). And if your not keen enough to see, I have changed my name from julian carlo to carlo julian, whats the point? Well, since I will be posting my poems, essays, and other writings here starting now, I just thought it would be cool to have that as my pseudonym. In case you dont know, which Im sure a lot of you dont, julian means youthful and carlo means matured, cool huh? And so, If I put the carlo first(matured) before the julian(youthful), then I might actually be able to focus on some hidden thins about me that even I am not aware about. Am I starting to sound crazy?  Just to let you know, I just started college taking up Biology here in  urlLink Silliman University . It has been a roller coaster month(June). I dont have my computer with me though, Its all boxed up thousands of miles away from my dorm at home and I have no idea when my dad will have it shipped. Anyway, there are internet cafes on every block so there wouldnt be any problem on my part.  So, I guess thats about it for now, see you all later! =P  22766 \"I\"  It kills me. Everytime I see you Everytime you come close to me I can feel my heart skipping beats, slowing down .bradycardia  It hurts me. When you look at me Seeing those pair of innocent eyes piercing through my soul can you see me? the real me? .skeptic  Everyday I look for you, I find you You speak to me I smile .It completes me'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
